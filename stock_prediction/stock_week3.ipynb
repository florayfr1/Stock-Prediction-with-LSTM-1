{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Week 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Add News Titles/headlines for the prediction</h3>\n",
    "\n",
    "\n",
    "<h1>In Progress</h1>\n",
    "\n",
    "<h3>\n",
    "-currently added the api and be able to convert the json response to dataframe\n",
    "</h3>\n",
    "<br>\n",
    "<h3>\n",
    "-next week plan to add that to the LSTM model\n",
    "</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stock Price Prediction And Forecasting Using Stacked LSTM- Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas_datareader as pdr\n",
    "#using tiingo library\n",
    "key=\"08b78fbc98302e995956e2d3b5b8f3c0296d32cc\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I choose these companies because I know them or I read news about them. \n",
    "There are no particular reasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "stock = \"BURL\"#\"EW\"#\"SYK\"#\"BACHF\"#\"NTTYY\"#\"INTC\"#\"DIS\"#\"TSLA\"#\"KEY\"#\"MSI\"#\"NVDA\"#\"AAPL\"#\"COST\"#\"AMZN\"#\"RIVN\"#\"GLD\"#\"RPRX\"#\"WDAY\"#\"CVX\"#\"FND\"\n",
    "#\"ADBE\"#\"AAPL\"#TDS\"#\"CLVT\"#\"RPRX\"#\"T\"#\"PHUN\"#\"ARDX\"#\"HPQ\"#\"CLVT\"#\"LGIH\"#\"FB\"#\"ORCL\"#\"MSFT\"#\"TDS\"#\"AMD\"#\"TM\"#\"DELL\"#\"COST\"#\"ABC\"#\"ABBV\"\n",
    "df = pdr.get_data_tiingo(stock, api_key=key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(f'{stock}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(f'{stock}.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2016-12-05'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Getting the start date of the stock data\n",
    "import datetime\n",
    "\n",
    "start_date=df.iloc[0]['date']\n",
    "\n",
    "#start_date = datetime.datetime(start_date.year, start_date.month, start_date.day)\n",
    "start_date = start_date.split(' ')\n",
    "start_date = start_date[0]\n",
    "start_date #type str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2021-12-03'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df.tail()\n",
    "\n",
    "#Getting the end date of the stock data\n",
    "\n",
    "end_date=df.iloc[len(df)-1]['date']\n",
    "#start_date = datetime.datetime(start_date.year, start_date.month, start_date.day)\n",
    "end_date = end_date.split(' ')\n",
    "end_date = end_date[0]\n",
    "\n",
    "end_date #type str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "#Convert str format date to datetime object for easy calculation\n",
    "def str_to_date(strdate):\n",
    "    return datetime.strptime(strdate, '%Y-%m-%d')\n",
    "\n",
    "#start_date = str_to_date(start_date)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert datetime object to str for easy documentation\n",
    "def date_to_str(datet):\n",
    "    return datet.strftime('%m/%d/%Y')\n",
    "\n",
    "#date_to_str(start_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>\n",
    "GoogleNews API cannot provide headlines from the past date without a search\n",
    "</h3>\n",
    "<br>\n",
    "<h3>\n",
    "Then, I try NewsAPI. However, to acquire data from time range as far as 2016 will require pay membership.  \n",
    "</h3>\n",
    "<br>\n",
    "<h3>\n",
    "Last, I try the NewYorkTime API which allow access to past data and return the month of news\n",
    "</h3>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from GoogleNews import GoogleNews\n",
    "\n",
    "#from datetime import timedelta\n",
    "'''\n",
    "googlenews = GoogleNews(lang='en')\n",
    "current_day = start_date\n",
    "next_day = date_to_str(str_to_date(start_date) + +timedelta(days=1)) \n",
    "googlenews.set_time_range(start_date,next_day)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#googlenews.search('finance')\n",
    "#googlenews.get_texts()\n",
    "#results = googlenews.results(sort=True)\n",
    "#results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pynytimes import NYTAPI\n",
    "\n",
    "#New York Times API\n",
    "nyt = NYTAPI(\"9xQE7W9DGO8r6GT8SwCdSTDqEVQTjdO4\", parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use pickle library for easy access and store\n",
    "# \n",
    "# Since all news from each month will be the same, so data can be reuse \n",
    "\n",
    "import pickle\n",
    "def save_net(savedfile,path):\n",
    "    with open(path, 'wb') as f:\n",
    "        pickle.dump(savedfile, f)\n",
    "    #print(f'Pickle file saved for Forum {forum_id} at {path}...')\n",
    "    return path\n",
    "\n",
    "def get_net(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        load = pickle.load(f)\n",
    "        #print('retrieved!')\n",
    "    return load\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Return filename in a specific format \n",
    "#so I can check if it exist in the file system\n",
    "\n",
    "def get_file_name(date):\n",
    "    current = date_to_str(date)\n",
    "    current = current.split(\"/\")\n",
    "    current_m, current_yr = current[0],current[2]\n",
    "    filename = f'{current_m}_{current_yr}_news.pckl'\n",
    "    #('%m/%d/%Y')\n",
    "    return filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import os.path\n",
    "from os import path\n",
    "\n",
    "#NYT API only need month and year\n",
    "#To ensure the accuracy of the date, I reset the first date to the first day of the month\n",
    "#Avoiding complcation in the month of Feburary\n",
    "current_date = str_to_date(start_date).replace(day=1)\n",
    "a_month = relativedelta(months=1) \n",
    "\n",
    "#request achieve news only if it does not already exist in the local path\n",
    "while current_date <=  str_to_date(end_date):\n",
    "    fn = get_file_name(current_date)\n",
    "    if not path.isfile(fn):\n",
    "        newsdata = nyt.archive_metadata(\n",
    "            current_date\n",
    "        )\n",
    "        save_net(newsdata,fn)\n",
    "    \n",
    "    current_date = current_date + a_month"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>\n",
    "The following is testing on a single file that contains news from December of 2016\n",
    "</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the news\n",
    "news_result = get_net('12_2016_news.pckl')\n",
    "#print(len(news_result))\n",
    "#news_result #Output is too large for github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>headlines</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12/01/2016</td>\n",
       "      <td>Trump, a Free-Form Leader, Experiments and Inv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12/01/2016</td>\n",
       "      <td>Guggenheim Helsinki Museum Plans Are Rejected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12/01/2016</td>\n",
       "      <td>Recount Bids in 3 States Seem the Longest of L...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12/01/2016</td>\n",
       "      <td>Records of Bill de Blasio's Helicopter Flights</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12/01/2016</td>\n",
       "      <td>Mayor de Blasioâ€™s Trips by Police Helicopter R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4962</th>\n",
       "      <td>12/31/2016</td>\n",
       "      <td>U.N. Encourages, but Stops Short of Endorsing,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4963</th>\n",
       "      <td>12/31/2016</td>\n",
       "      <td>F. Ross Johnson, Symbol of â€™80s Corporate Exce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4964</th>\n",
       "      <td>12/31/2016</td>\n",
       "      <td>Rolling in the Aisles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4965</th>\n",
       "      <td>12/31/2016</td>\n",
       "      <td>Chief Justice Salutes Trial Judges for Tacklin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4966</th>\n",
       "      <td>12/31/2016</td>\n",
       "      <td>Terrorist Attack at Nightclub in Istanbul Kill...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4967 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date                                          headlines\n",
       "0     12/01/2016  Trump, a Free-Form Leader, Experiments and Inv...\n",
       "1     12/01/2016      Guggenheim Helsinki Museum Plans Are Rejected\n",
       "2     12/01/2016  Recount Bids in 3 States Seem the Longest of L...\n",
       "3     12/01/2016     Records of Bill de Blasio's Helicopter Flights\n",
       "4     12/01/2016  Mayor de Blasioâ€™s Trips by Police Helicopter R...\n",
       "...          ...                                                ...\n",
       "4962  12/31/2016  U.N. Encourages, but Stops Short of Endorsing,...\n",
       "4963  12/31/2016  F. Ross Johnson, Symbol of â€™80s Corporate Exce...\n",
       "4964  12/31/2016                              Rolling in the Aisles\n",
       "4965  12/31/2016  Chief Justice Salutes Trial Judges for Tacklin...\n",
       "4966  12/31/2016  Terrorist Attack at Nightclub in Istanbul Kill...\n",
       "\n",
       "[4967 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#Convert the json file into dataframe for easier data process\n",
    "\n",
    "headline_df = pd.DataFrame(columns={'date','headlines'})\n",
    "\n",
    "data_list = []\n",
    "for x in news_result:\n",
    "    #current_date = date_to_str(x['pub_date']) #str\n",
    "    current_date = date_to_str(x['pub_date']) #datetime\n",
    "    day_headline = (x['headline']['main']) \n",
    "    if day_headline == '':\n",
    "        break\n",
    "    container = {'date':current_date,'headlines':day_headline}\n",
    "    data_list.append(container)\n",
    "\n",
    "\n",
    "    #if len(data_list) == 5: \n",
    "    #    break\n",
    "\n",
    "\n",
    "headline_df = pd.DataFrame(data_list)\n",
    "headline_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>\n",
    "Since each date have more than one news, I would want to group it by date when put it in my machine learning model\n",
    "</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headlines</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12/01/2016</th>\n",
       "      <td>Trump, a Free-Form Leader, Experiments and Inv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12/02/2016</th>\n",
       "      <td>Russian Spacecraft Carrying Supplies Burns Up ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12/03/2016</th>\n",
       "      <td>Itâ€™s Trumpâ€™s Economy Now. What Will He Do With...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12/04/2016</th>\n",
       "      <td>Jill Steinâ€™s Pennsylvania Recount Effort Is De...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12/05/2016</th>\n",
       "      <td>Shadows Fall and Jaws Drop for a Jolly Green I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12/06/2016</th>\n",
       "      <td>Dylann Roofâ€™s Letter to the Court</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12/07/2016</th>\n",
       "      <td>Aska</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12/08/2016</th>\n",
       "      <td>Wary Corporate Chiefs Keep an Ear Tuned to Tru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12/09/2016</th>\n",
       "      <td>U.N. Says Nearly One in Four Children Live in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12/10/2016</th>\n",
       "      <td>â€˜Restaurant Recessionâ€™ From Health Care Act? L...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12/11/2016</th>\n",
       "      <td>Bob Dylanâ€™s Nobel Prize Acceptance Speech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12/12/2016</th>\n",
       "      <td>â€˜Could You Patent the Sun?â€™</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12/13/2016</th>\n",
       "      <td>Cathedral Bombing in Cairo Leaves Egypt Alarme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12/14/2016</th>\n",
       "      <td>Court Debates Which Cosby Accusers May Testify</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12/15/2016</th>\n",
       "      <td>Fox News Names New Head of Human Resources</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12/16/2016</th>\n",
       "      <td>Film Series in NYC This Week</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12/17/2016</th>\n",
       "      <td>Prosecutors Drop Inquiry Into Charles Hynes, F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12/18/2016</th>\n",
       "      <td>Trump Ends â€˜Thank Youâ€™ Tour on Familiar Theme:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12/19/2016</th>\n",
       "      <td>Hungry, Thirsty and Bloodied in Battle to Reta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12/20/2016</th>\n",
       "      <td>Book Deal for Pantsuit Nation, Facebook Page S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12/21/2016</th>\n",
       "      <td>Nielsen Acquires Gracenote, Highlighting the V...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12/22/2016</th>\n",
       "      <td>In Kansas, Where Republicans and Fiscal Woes R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12/23/2016</th>\n",
       "      <td>Whatâ€™s New in NYC Theater</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12/24/2016</th>\n",
       "      <td>Businesses Near Trump Tower Say Security Is St...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12/25/2016</th>\n",
       "      <td>Giants Idly Clinch Playoff Spot, Through a Tam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12/26/2016</th>\n",
       "      <td>Treasury Auctions Set for the Week of Dec. 26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12/27/2016</th>\n",
       "      <td>California, at Forefront of Climate Fight, Won...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12/28/2016</th>\n",
       "      <td>Art Thatâ€™s Disposable, but by No Means Throwaway</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12/29/2016</th>\n",
       "      <td>Video Blogger Who Tested Singaporeâ€™s Limits Se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12/30/2016</th>\n",
       "      <td>Art and Museums in NYC This Week</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12/31/2016</th>\n",
       "      <td>Cub Scouts Kick Out Transgender Boy in New Jersey</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    headlines\n",
       "date                                                         \n",
       "12/01/2016  Trump, a Free-Form Leader, Experiments and Inv...\n",
       "12/02/2016  Russian Spacecraft Carrying Supplies Burns Up ...\n",
       "12/03/2016  Itâ€™s Trumpâ€™s Economy Now. What Will He Do With...\n",
       "12/04/2016  Jill Steinâ€™s Pennsylvania Recount Effort Is De...\n",
       "12/05/2016  Shadows Fall and Jaws Drop for a Jolly Green I...\n",
       "12/06/2016                  Dylann Roofâ€™s Letter to the Court\n",
       "12/07/2016                                               Aska\n",
       "12/08/2016  Wary Corporate Chiefs Keep an Ear Tuned to Tru...\n",
       "12/09/2016  U.N. Says Nearly One in Four Children Live in ...\n",
       "12/10/2016  â€˜Restaurant Recessionâ€™ From Health Care Act? L...\n",
       "12/11/2016          Bob Dylanâ€™s Nobel Prize Acceptance Speech\n",
       "12/12/2016                        â€˜Could You Patent the Sun?â€™\n",
       "12/13/2016  Cathedral Bombing in Cairo Leaves Egypt Alarme...\n",
       "12/14/2016     Court Debates Which Cosby Accusers May Testify\n",
       "12/15/2016         Fox News Names New Head of Human Resources\n",
       "12/16/2016                       Film Series in NYC This Week\n",
       "12/17/2016  Prosecutors Drop Inquiry Into Charles Hynes, F...\n",
       "12/18/2016  Trump Ends â€˜Thank Youâ€™ Tour on Familiar Theme:...\n",
       "12/19/2016  Hungry, Thirsty and Bloodied in Battle to Reta...\n",
       "12/20/2016  Book Deal for Pantsuit Nation, Facebook Page S...\n",
       "12/21/2016  Nielsen Acquires Gracenote, Highlighting the V...\n",
       "12/22/2016  In Kansas, Where Republicans and Fiscal Woes R...\n",
       "12/23/2016                          Whatâ€™s New in NYC Theater\n",
       "12/24/2016  Businesses Near Trump Tower Say Security Is St...\n",
       "12/25/2016  Giants Idly Clinch Playoff Spot, Through a Tam...\n",
       "12/26/2016      Treasury Auctions Set for the Week of Dec. 26\n",
       "12/27/2016  California, at Forefront of Climate Fight, Won...\n",
       "12/28/2016   Art Thatâ€™s Disposable, but by No Means Throwaway\n",
       "12/29/2016  Video Blogger Who Tested Singaporeâ€™s Limits Se...\n",
       "12/30/2016                   Art and Museums in NYC This Week\n",
       "12/31/2016  Cub Scouts Kick Out Transgender Boy in New Jersey"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#Grouping the headlines by date\n",
    "\n",
    "headline_df = headline_df.groupby('date')\n",
    "headline_df.first()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Week 3 Conclusion</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>\n",
    "The rest are same as last week\n",
    "I have not have the chance to finish adding the news dataframes to the model yet\n",
    "</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>\n",
    "Our next goal is combining dataframe together\n",
    "For example, it should contain \"date, close price, headlines...\"\n",
    "Then I will apply LSTM to predict the close price\n",
    "</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#value to predict\n",
    "df_closePrice = df.reset_index()['close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_closePrice.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(df_closePrice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LSTM is sensitive to the scale \n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# use MinMax scalar to transform the value between 0 and 1\n",
    "scaler=MinMaxScaler(feature_range=(0,1))\n",
    "df_closePrice=scaler.fit_transform(np.array(df_closePrice).reshape(-1,1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converted to array of values between 0 and 1 \n",
    "df_closePrice "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make train test split\n",
    "split_percentage = 0.65\n",
    "training_size = int(len(df_closePrice)*split_percentage)\n",
    "test_size=len(df_closePrice)-training_size\n",
    "#split the dataframe\n",
    "train_data = df_closePrice[0:training_size,:]\n",
    "test_data = df_closePrice[training_size:len(df_closePrice),:1]\n",
    "\n",
    "print(len(train_data))\n",
    "print(len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# This method is use to separate the data in the order of its timeline\n",
    "\t#for example, \n",
    "\t#Train: 1, 2, 4, 1, 5, 6 \n",
    "\t#will return 1, 2, 4, 1 (train_x); 5, 6 (train_y)\n",
    "#This will preserve the time in the model,\n",
    "#so we cannot use the future to predict the past\n",
    "def create_dataset(dataset, time_step=1):\n",
    "\tx, y = [], []\n",
    "\tfor i in range(len(dataset)-time_step-1):\n",
    "\t\ta = dataset[i:(i+time_step), 0]   ###i=0, 0,1,2,3-----99   100 \n",
    "\t\tx.append(a)\n",
    "\t\ty.append(dataset[i + time_step, 0])\n",
    "\treturn np.array(x), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape into X=t,t+1,t+2,t+3 and Y=t+4\n",
    "\n",
    "#change from 100 to 150\n",
    "\n",
    "time_step = 150 #more the better; train test split\n",
    "\n",
    "train_x, train_y = create_dataset(train_data, time_step)\n",
    "test_x, test_y = create_dataset(test_data, time_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_x.shape), print(train_y.shape)\n",
    "print(test_x.shape), print(test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reshape input \n",
    "train_x =train_x.reshape(train_x.shape[0],train_x.shape[1] , 1)\n",
    "test_x = test_x.reshape(test_x.shape[0],test_x.shape[1] , 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create the Stacked LSTM model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating nested LSTM model\n",
    "from tensorflow.keras.layers import Bidirectional\n",
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "#change layer input from 100 to 150\n",
    "\n",
    "#CHANGE \n",
    "    #Add Bidirectional LSTM layer\n",
    "    #Add Dropout regularization\n",
    "    #Add activation functio nin each layer\n",
    "\n",
    "#parameter obtain from the paper\n",
    "    #http://cs230.stanford.edu/projects_winter_2020/reports/32066186.pdf\n",
    "\n",
    "model.add(Bidirectional(LSTM(50,return_sequences=True,activation=\"tanh\"),input_shape=(150,1)))\n",
    "model.add(Bidirectional(LSTM(50,return_sequences=True)))\n",
    "model.add(Bidirectional(LSTM(50,dropout=0.2)))\n",
    "#model.add(Bidirectional(LSTM(50,activation=\"tanh\")))\n",
    "#add sigmoid\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='mean_squared_error',optimizer='adam')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_x,train_y,validation_data=(test_x,test_y),epochs=100,batch_size=64,verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "train_predict = model.predict(train_x)\n",
    "test_predict = model.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transform back to original data range\n",
    "#from (0,1) back to original range\n",
    "\n",
    "train_predict=scaler.inverse_transform(train_predict)\n",
    "test_predict=scaler.inverse_transform(test_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Calculate RMSE performance metrics\n",
    "import math\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "#result for training dataset\n",
    "math.sqrt(mean_squared_error(train_y,train_predict))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Test Data RMSE\n",
    "math.sqrt(mean_squared_error(test_y,test_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predict.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plotting \n",
    "# shift train predictions for plotting\n",
    "\n",
    "#CHANGE look back change from 100 to 150\n",
    "\n",
    "look_back=150\n",
    "trainPredictPlot = np.empty_like(df_closePrice)\n",
    "trainPredictPlot[:, :] = np.nan\n",
    "trainPredictPlot[look_back:len(train_predict)+look_back, :] = train_predict\n",
    "# shift test predictions for plotting\n",
    "testPredictPlot = np.empty_like(df_closePrice)\n",
    "testPredictPlot[:, :] = np.nan\n",
    "testPredictPlot[len(train_predict)+(look_back*2)+1:len(df_closePrice)-1, :] = test_predict\n",
    "# plot baseline and predictions\n",
    "plt.plot(scaler.inverse_transform(df_closePrice))\n",
    "plt.plot(trainPredictPlot)\n",
    "plt.plot(testPredictPlot)\n",
    "plt.show()\n",
    "\n",
    "#test predict is green\n",
    "#blue is the whole data set\n",
    "#orange is the train predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction\n",
    "\n",
    "#Change look\n",
    "start_point = len(test_data) -look_back\n",
    "#use 100 data poin to predict\n",
    "x_input=test_data[start_point:].reshape(1,-1)\n",
    "x_input.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_input=list(x_input)\n",
    "temp_input=temp_input[0].tolist() #all the test_data with previous 100 data point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# demonstrate prediction for next 30 days\n",
    "from numpy import array\n",
    "\n",
    "lst_output=[]\n",
    "n_steps=150\n",
    "i=0\n",
    "\n",
    "# CHANGE\n",
    "date_predict = 30\n",
    "while(i<date_predict):\n",
    "    \n",
    "    if(len(temp_input)>150):\n",
    "        #if more than 150 data point shift the list to contain only 150 datapoint\n",
    "\n",
    "        #print(temp_input)\n",
    "        x_input=np.array(temp_input[1:]) #shifting one poistion to the right\n",
    "        print(\"{} day input {}\".format(i,x_input))\n",
    "        x_input=x_input.reshape(1,-1)\n",
    "        x_input = x_input.reshape((1, n_steps, 1))\n",
    "        #print(x_input)\n",
    "        y_pred = model.predict(x_input, verbose=0)\n",
    "        print(\"{} day output {}\".format(i,y_pred))\n",
    "        temp_input.extend(y_pred[0].tolist())\n",
    "        temp_input=temp_input[1:]\n",
    "        #print(temp_input)\n",
    "        lst_output.extend(y_pred.tolist())\n",
    "        i=i+1\n",
    "    else:\n",
    "        #use the 100 data point to predict\n",
    "        x_input = x_input.reshape((1, n_steps,1)) #reshape the data\n",
    "        y_pred = model.predict(x_input, verbose=0)\n",
    "        print(y_pred[0])\n",
    "        temp_input.extend(y_pred[0].tolist())\n",
    "        print(len(temp_input))\n",
    "\n",
    "        #add to the temp_input\n",
    "        lst_output.extend(y_pred.tolist()) \n",
    "        i=i+1\n",
    "    \n",
    "\n",
    "print(lst_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#start plotting the new 30 predictions\n",
    "day_new=np.arange(1,151)\n",
    "day_pred=np.arange(151,181)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_start = len(df_closePrice) - 150\n",
    "\n",
    "plt.plot(day_new,scaler.inverse_transform(df_closePrice[total_start:])) #use the previous 150 data\n",
    "plt.plot(day_pred,scaler.inverse_transform(lst_output))\n",
    "plt.title(stock)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine to the whole data\n",
    "df3=df_closePrice.tolist()\n",
    "df3.extend(lst_output)\n",
    "view_point = len(df_closePrice)-50\n",
    "plt.plot(df3[view_point:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://towardsdatascience.com/stock-market-action-prediction-with-convnet-8689238feae3\n",
    "#https://towardsdatascience.com/predicting-stock-price-with-lstm-13af86a74944\n",
    "#Future plan use new headline as a feature\n",
    "    #challenge : how to label?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ef1a5d0b392b78fa6b938496ed158b31a5708e64beeadf2ab287f2b43192d531"
  },
  "kernelspec": {
   "display_name": "Python 3.8.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
