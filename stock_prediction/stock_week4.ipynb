{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Week 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Add News Titles/headlines for the prediction</h3>\n",
    "\n",
    "\n",
    "<h3>\n",
    "Using Random Forest to predict if I will lose or gain money\n",
    "Need the buy price\n",
    "</h3>\n",
    "<br>\n",
    "<h3>\n",
    "Did not use LSTM\n",
    "</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stock Price Prediction And Forecasting Using Stacked LSTM- Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas_datareader as pdr\n",
    "#using tiingo library\n",
    "key=\"08b78fbc98302e995956e2d3b5b8f3c0296d32cc\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I choose these companies because I know them or I read news about them. \n",
    "There are no particular reasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "stock = \"BURL\"#\"EW\"#\"SYK\"#\"BACHF\"#\"NTTYY\"#\"INTC\"#\"DIS\"#\"TSLA\"#\"KEY\"#\"MSI\"#\"NVDA\"#\"AAPL\"#\"COST\"#\"AMZN\"#\"RIVN\"#\"GLD\"#\"RPRX\"#\"WDAY\"#\"CVX\"#\"FND\"\n",
    "#\"ADBE\"#\"AAPL\"#TDS\"#\"CLVT\"#\"RPRX\"#\"T\"#\"PHUN\"#\"ARDX\"#\"HPQ\"#\"CLVT\"#\"LGIH\"#\"FB\"#\"ORCL\"#\"MSFT\"#\"TDS\"#\"AMD\"#\"TM\"#\"DELL\"#\"COST\"#\"ABC\"#\"ABBV\"\n",
    "df = pdr.get_data_tiingo(stock, api_key=key)\n",
    "\n",
    "buy = 173.69"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(f'{stock}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(f'{stock}.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2016-12-12'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Getting the start date of the stock data\n",
    "import datetime\n",
    "\n",
    "start_date=df.iloc[0]['date']\n",
    "\n",
    "#start_date = datetime.datetime(start_date.year, start_date.month, start_date.day)\n",
    "start_date = start_date.split(' ')\n",
    "start_date = start_date[0]\n",
    "start_date #type str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2021-12-08'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df.tail()\n",
    "\n",
    "#Getting the end date of the stock data\n",
    "\n",
    "end_date=df.iloc[len(df)-1]['date']\n",
    "#start_date = datetime.datetime(start_date.year, start_date.month, start_date.day)\n",
    "end_date = end_date.split(' ')\n",
    "end_date = end_date[0]\n",
    "\n",
    "end_date #type str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "#Convert str format date to datetime object for easy calculation\n",
    "def str_to_date(strdate):\n",
    "    return datetime.strptime(strdate, '%Y-%m-%d')\n",
    "\n",
    "def strD_to_date(strdate):\n",
    "    return datetime.strptime(strdate, '%m/%d/%Y')\n",
    "\n",
    "def str_to_str(strdate):\n",
    "    # 2016-12-09 00:00:00+00:00\n",
    "    strdate = strdate.split(' ')\n",
    "    strdate = strdate[0]\n",
    "    return date_to_str(datetime.strptime(strdate, '%Y-%m-%d'))\n",
    "\n",
    "#start_date = str_to_date(start_date)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert datetime object to str for easy documentation\n",
    "def date_to_str(datet):\n",
    "    return datet.strftime('%m/%d/%Y')\n",
    "\n",
    "#date_to_str(start_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pynytimes import NYTAPI\n",
    "\n",
    "#New York Times API\n",
    "nyt = NYTAPI(\"9xQE7W9DGO8r6GT8SwCdSTDqEVQTjdO4\", parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use pickle library for easy access and store\n",
    "# \n",
    "# Since all news from each month will be the same, so data can be reuse \n",
    "\n",
    "import pickle\n",
    "def save_net(savedfile,path):\n",
    "    with open(path, 'wb') as f:\n",
    "        pickle.dump(savedfile, f)\n",
    "    #print(f'Pickle file saved for Forum {forum_id} at {path}...')\n",
    "    return path\n",
    "\n",
    "def get_net(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        load = pickle.load(f)\n",
    "        #print('retrieved!')\n",
    "    return load\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Return filename in a specific format \n",
    "#so I can check if it exist in the file system\n",
    "\n",
    "def get_file_name(date):\n",
    "    current = date_to_str(date)\n",
    "    current = current.split(\"/\")\n",
    "    current_m, current_yr = current[0],current[2]\n",
    "    filename = f'{current_m}_{current_yr}_news.pckl'\n",
    "    #('%m/%d/%Y')\n",
    "    return filename\n",
    "\n",
    "def get_yr_from_file(fn):\n",
    "    current = fn.split(\"_\")\n",
    "    current_yr = current[1]\n",
    "    return current_yr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of                            date   close\n",
       "0     2016-12-12 00:00:00+00:00   87.60\n",
       "1     2016-12-13 00:00:00+00:00   87.21\n",
       "2     2016-12-14 00:00:00+00:00   87.23\n",
       "3     2016-12-15 00:00:00+00:00   87.87\n",
       "4     2016-12-16 00:00:00+00:00   87.06\n",
       "...                         ...     ...\n",
       "1252  2021-12-02 00:00:00+00:00  293.00\n",
       "1253  2021-12-03 00:00:00+00:00  288.56\n",
       "1254  2021-12-06 00:00:00+00:00  288.15\n",
       "1255  2021-12-07 00:00:00+00:00  293.32\n",
       "1256  2021-12-08 00:00:00+00:00  289.85\n",
       "\n",
       "[1257 rows x 2 columns]>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#value to predict\n",
    "df_closePrice = df.reset_index()[['date','close']]\n",
    "df_closePrice.head\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>This takes too long to run</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "<bound method NDFrame.head of     close                                          headlines\n",
      "0   84.78  [Dylann Roof, Charleston Church Killer, Is Dee...\n",
      "1   86.88  [Call to Centralize Security in Germany Broach...\n",
      "2   87.13  [Rockefeller Foundation Picks Rajiv J. Shah, a...\n",
      "3   85.35  [Changes Ahead for Conan O’Brien’s Late-Night ...\n",
      "4   85.49  [The Rev. Sharonda Coleman-Singleton praying, ...\n",
      "5   87.39  [Can India Put an End to Identity Politics?, N...\n",
      "6   85.54  [Trump Received Unsubstantiated Report That Ru...\n",
      "7   85.31  [Trump Promises Fast Action on Supreme Court N...\n",
      "8   84.75  [Dance in NYC This Week, Art and Museums in NY...\n",
      "9   83.87  [Interior Nominee Promotes Navy SEAL Career, W...\n",
      "10  84.32  [Land Rush in Permian Basin, Where Oil Is Stac...\n",
      "11  83.33  [For Nicky Jam, a Second Chance at Stardom as ...\n",
      "12  83.17  [Henry J. Foner, Labor Leader Accused of Commu...\n",
      "13  82.71  [Protests in Bangladesh Shake a Global Worksho...\n",
      "14  83.59  [New York Police Plan $275 Million Update to T...\n",
      "15  84.48  [M.T.A. Chief’s Departure Leaves Void at Top o...\n",
      "16  82.04  [For Justin Trudeau, Canada’s Leader, Revival ...\n",
      "17  80.91  [Child Welfare Unit Tied to Toddler’s Death Is...\n",
      "18  81.64  [There’s Halftime. Then There’s ‘Showtime.’ We...\n",
      "19  83.70  [Syria Reclaims Damascus Water Source From Reb...>\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "fn = '01_2017_news.pckl'\n",
    "def get_news(filename):\n",
    "    news_result = get_net(filename)\n",
    "    #Convert the json file into dataframe for easier data process\n",
    "\n",
    "    headline_df = pd.DataFrame(columns={'date','headlines'})\n",
    "\n",
    "    data_list = []\n",
    "    for x in news_result:\n",
    "        #current_date = date_to_str(x['pub_date']) #str\n",
    "        current_date = date_to_str(x['pub_date']) #datetime\n",
    "        day_headline = (x['headline']['main']) \n",
    "        if day_headline == '':\n",
    "            break\n",
    "        container = {'date':current_date,'headlines':day_headline}\n",
    "        data_list.append(container)\n",
    "\n",
    "    headline_df = pd.DataFrame(data_list)\n",
    "\n",
    "    headlines_dict = defaultdict(list)\n",
    "\n",
    "    \"\"\" for index2, row2 in df_closePrice.iterrows():\n",
    "       \n",
    "        if get_yr_from_file(filename) not in str_to_str(row2['date']):\n",
    "            continue\n",
    "            \n",
    "        \n",
    "        for index, row in headline_df.iterrows():\n",
    "            if row['date'] == str_to_str(row2['date']):\n",
    "                headlines_dict[row2['close']].append(row['headlines']) \"\"\"\n",
    "\n",
    "    for index, row in headline_df.iterrows():\n",
    "    \n",
    "        for index2, row2 in df_closePrice.iterrows():\n",
    "            \n",
    "            if get_yr_from_file(filename) not in str_to_str(row2['date']):\n",
    "                continue\n",
    "            \n",
    "            if row['date'] == str_to_str(row2['date']):\n",
    "                headlines_dict[row2['close']].append(row['headlines'])\n",
    "                \n",
    "\n",
    "    print(len(headlines_dict)) #num of days in a month where market open\n",
    "    \n",
    "    result = pd.DataFrame(headlines_dict.items(), columns=['close', 'headlines'])\n",
    "    #result.to_csv(\"plzzz.csv\")\n",
    "    print(result.head)\n",
    "    #return headlines_dict\n",
    "\n",
    "get_news(fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>This will give you extremely LARGE amount of files</h3>\n",
    "<h4>Data ranging from 2016 to 2021</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import os.path\n",
    "from os import path\n",
    "\n",
    "#NYT API only need month and year\n",
    "#To ensure the accuracy of the date, I reset the first date to the first day of the month\n",
    "#Avoiding complcation in the month of Feburary\n",
    "current_date = str_to_date(start_date).replace(day=1)\n",
    "a_month = relativedelta(months=1) \n",
    "total_dict = {}\n",
    "\n",
    "\n",
    "#request achieve news only if it does not already exist in the local path\n",
    "while current_date <=  str_to_date(end_date):\n",
    "    fn = get_file_name(current_date)\n",
    "    if not path.isfile(fn):\n",
    "        newsdata = nyt.archive_metadata(\n",
    "            current_date\n",
    "        )\n",
    "        save_net(newsdata,fn)\n",
    "    total_dict.update(get_news(fn))\n",
    "    \n",
    "    current_date = current_date + a_month\n",
    "\n",
    "df_data = pd.DataFrame(total_dict.items(), columns=['close', 'headlines'])\n",
    "df_data.head\n",
    "print(len(df_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>\n",
    "Also practice on the KAggle challenge\n",
    "</h3>\n",
    "\n",
    "<h3>\n",
    "This will only compare/predict to the buy price and its using random forest \n",
    "</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train = df_data[df_data['date'] < '01/01/2020']\n",
    "test = df_data[df_data['date'] > '12/31/2019']\n",
    "\n",
    "train_label = []\n",
    "test_label = []\n",
    "for index_temp, row_temp in df_data.iterrows():\n",
    "    if row_temp['close'] > buy and df_data['date'] < '01/01/2020':\n",
    "        train_label.append('1')\n",
    "    elif row_temp['close'] > buy and df_data['date'] > '12/31/2019':\n",
    "        test_label.append('1')\n",
    "    elif row_temp['close'] < buy and df_data['date'] > '12/31/2019':\n",
    "        test_label.append('0')\n",
    "    else:\n",
    "        train_label.append('0')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing special characters\n",
    "data=train.iloc[:,2:27]\n",
    "data.replace(\"[^a-zA-Z]\",\" \",regex=True, inplace=True)\n",
    "# Renaming column names for better understanding and ease of access\n",
    "list1= [i for i in range(25)]\n",
    "new_Index=[str(i) for i in list1]\n",
    "data.columns= new_Index\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in new_Index:\n",
    "    data[index] = data[index].str.lower()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headlines = []\n",
    "for row in range(0,len(data.index)):\n",
    "    headlines.append(' '.join(str(x) for x in data.iloc[row,0:25]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Processing words from headlines</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "## implement BAG OF WORDS\n",
    "\n",
    "countvector=CountVectorizer(ngram_range=(2,2))\n",
    "traindataset=countvector.fit_transform(headlines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "seed = 50\n",
    "\n",
    "## implement RandomForest Classifier\n",
    "randomclassifier = RandomForestClassifier(\n",
    "                      min_samples_leaf=50,\n",
    "                      n_estimators=150,\n",
    "                      bootstrap=False,\n",
    "                      oob_score=False,\n",
    "                      class_weight='balanced_subsample',\n",
    "                      n_jobs=-1,\n",
    "                      random_state=seed,\n",
    "                      max_features='auto')\n",
    "\n",
    "randomclassifier.fit(traindataset,train['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transform= []\n",
    "for row in range(0,len(test.index)):\n",
    "    test_transform.append(' '.join(str(x) for x in test.iloc[row,2:27]))\n",
    "test_dataset = countvector.transform(test_transform)\n",
    "y_pred = randomclassifier.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(test_label, y_pred)\n",
    "recall = recall_score(test_label, y_pred)\n",
    "precision = precision_score(test_label, y_pred)\n",
    "f1 = f1_score(test_label, y_pred)\n",
    "\n",
    "print(\"Random Forest\")\n",
    "print(f\"The accuracy of the model is {round(accuracy,3)*100} %\")\n",
    "print(f\"The recall of the model is {round(recall,3)*100} %\")\n",
    "print(f\"The precision of the model is {round(precision,3)*100} %\")\n",
    "print(f\"The f1 of the model is {round(f1,3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, roc_auc_score, roc_curve, f1_score\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def evaluate_model(y_pred, probs,train_predictions, train_probs):\n",
    "    baseline = {}\n",
    "    baseline['recall']=recall_score(test_label,\n",
    "                    [1 for _ in range(len(test_label))])\n",
    "    baseline['precision'] = precision_score(test_label,\n",
    "                    [1 for _ in range(len(test_label))])\n",
    "    baseline['roc'] = 0.5\n",
    "    results = {}\n",
    "    results['recall'] = recall_score(test_label, y_pred)\n",
    "    results['precision'] = precision_score(test_label, y_pred)\n",
    "    results['roc'] = roc_auc_score(test_label, probs)\n",
    "    train_results = {}\n",
    "    train_results['recall'] = recall_score(train_label,       train_predictions)\n",
    "    train_results['precision'] = precision_score(train_label, train_predictions)\n",
    "    train_results['roc'] = roc_auc_score(train_label, train_probs)\n",
    "    for metric in ['recall', 'precision', 'roc']: \n",
    "          print(f'{metric.capitalize()}\\\n",
    "                 Baseline: {round(baseline[metric], 2)} \\\n",
    "                 Test: {round(results[metric], 2)} \\\n",
    "                 Train: {round(train_results[metric], 2)}')\n",
    "    # Calculate false positive rates and true positive rates\n",
    "    base_fpr, base_tpr, _ = roc_curve(test_label, [1 for _ in range(len(test_label))])\n",
    "    model_fpr, model_tpr, _ = roc_curve(test_label, probs)\n",
    "    plt.figure(figsize = (8, 6))\n",
    "    plt.rcParams['font.size'] = 16\n",
    "    # Plot both curves\n",
    "    plt.plot(base_fpr, base_tpr, 'b', label = 'baseline')\n",
    "    plt.plot(model_fpr, model_tpr, 'r', label = 'model')\n",
    "    plt.legend()\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate'); plt.title('ROC Curves')\n",
    "    plt.show()\n",
    "\n",
    "def plot_confusion_matrix(cm, classes, normalize = False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Greens): # can change color \n",
    "    plt.figure(figsize = (6, 6))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title, size = 12)\n",
    "    plt.colorbar(aspect=5)\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45, size = 8)\n",
    "    plt.yticks(tick_marks, classes, size = 8)\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    # Label the plot\n",
    "    for i, j in itertools.product(range(cm.shape[0]),   range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt), \n",
    "             fontsize = 10,\n",
    "             horizontalalignment=\"center\",\n",
    "             color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    plt.grid(None)\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label', size = 10)\n",
    "    plt.xlabel('Predicted label', size = 10)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "#evaluate_model(y_pred,probs,train_predictions,train_probs)\n",
    "\n",
    "#cm = confusion_matrix(test_label, y_pred)\n",
    "#plot_confusion_matrix(cm, classes = ['0 - Gain', '1 - Lose'],\n",
    "#                      title = 'Stock Confusion Matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Week 4 Conclusion</h1>\n",
    "\n",
    "<h3>\n",
    "I was not able to get the shape of the LSTM model to fit\n",
    "\n",
    "I was able to combine the headlines of the past, but it takes too long to process\n",
    "\n",
    "I was not able to make the model run on the full data because it needs too much CPU power\n",
    "</h3>\n",
    "\n",
    "<h3>\n",
    "If more time I want to improve my algorithm that search for match date in the headline\n",
    "\n",
    "Currently, I am using nested for loop that makes the time complexity sad\n",
    "\n",
    "I think switching to dictionary or use numpy array will give me a much better result\n",
    "</h3>"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ef1a5d0b392b78fa6b938496ed158b31a5708e64beeadf2ab287f2b43192d531"
  },
  "kernelspec": {
   "display_name": "Python 3.8.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
